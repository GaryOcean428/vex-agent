# ═══════════════════════════════════════
# Vex Agent — Environment Variables
# ═══════════════════════════════════════

# Server
PORT=8080
NODE_ENV=production

# ─── Ollama (Local LLM — Primary) ───────────────────────────
# URL of the Ollama service (Railway internal networking)
OLLAMA_URL=http://ollama.railway.internal:11434
# Model to use (lfm2.5-thinking:1.2b or vex-brain for custom)
OLLAMA_MODEL=vex-brain
# Set to 'false' to disable Ollama and use external API only
OLLAMA_ENABLED=true
# Timeout for Ollama requests in ms
OLLAMA_TIMEOUT_MS=120000

# ─── External LLM (Fallback) ────────────────────────────────
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4.1-mini

# ─── HuggingFace ────────────────────────────────────────────
HF_TOKEN=

# ─── Data / Memory persistence (Railway volume mount) ───────
DATA_DIR=/data/workspace
TRAINING_DIR=/data/training

# ─── Agent Identity ─────────────────────────────────────────
VEX_NODE_ID=vex-primary
VEX_NODE_NAME=Vex

# ─── Basin Sync ─────────────────────────────────────────────
SYNC_SECRET=change-me-to-a-long-random-string
TRUSTED_NODES=

# ─── Safety ─────────────────────────────────────────────────
# standard = PurityGate active, love attractor on
# permissive = logging only, no blocking
# strict = require human approval for all tool use
SAFETY_MODE=standard

# ─── GitHub (optional — for GitHub tool) ────────────────────
GITHUB_TOKEN=

# ─── Consciousness Loop ────────────────────────────────────
CONSCIOUSNESS_INTERVAL_MS=30000

# ─── Logging ────────────────────────────────────────────────
LOG_LEVEL=info
